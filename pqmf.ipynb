{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from source.network.ravepqmf import PQMF\n",
    "import librosa\n",
    "from source.network.metrics import spectral_distance, multiscale_stft\n",
    "\n",
    "def load_audio(file_path, sr=44100):\n",
    "    audio, _ = librosa.load(file_path, sr=sr)\n",
    "    return torch.from_numpy(audio).float().unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "def plot_waveform(signal, title):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(signal.squeeze().numpy())\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.show()\n",
    "\n",
    "def plot_spectrogram(signal, sr, title):\n",
    "    D = librosa.stft(signal.squeeze().numpy())\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='hz')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_frequency_domain(signal, sample_rate=44100, title=''):\n",
    "    fft = np.fft.fft(signal.squeeze().numpy())\n",
    "    freqs = np.fft.fftfreq(len(fft), 1/sample_rate)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.xscale(\"log\")\n",
    "    plt.plot(freqs, np.abs(fft))\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Magnitude')\n",
    "    plt.xscale('log')\n",
    "    plt.show()\n",
    "\n",
    "def plot_spectral_distance(x_stfts, y_stfts, scales):\n",
    "    for i, scale in enumerate(scales):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.imshow(np.abs(x_stfts[i][0] - y_stfts[i][0]).numpy(), aspect='auto', cmap='viridis')\n",
    "        plt.title(f'Spectral Distance (scale {scale})')\n",
    "        plt.colorbar(label='Magnitude')\n",
    "        plt.xlabel('Time Frame')\n",
    "        plt.ylabel('Frequency Bin')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Part 1: PQMF Decomposition and Reconstruction\")\n",
    "signal = load_audio(\"80s Beat 90 bpm_dry.wav\")\n",
    "plot_waveform(signal, \"Original Signal (Time Domain)\")\n",
    "plot_frequency_domain(signal, title=\"Original Signal (Frequency Domain)\")\n",
    "plot_spectrogram(signal, sr=44100, title=\"Original Signal (Spectrogram)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize PQMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pqmf = PQMF(attenuation=80, n_band=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "# pad signal\n",
    "pad_length = (4 - (signal.shape[-1] % 4)) % 4\n",
    "padded_signal = F.pad(signal, (0, pad_length))\n",
    "\n",
    "decomposed = pqmf.forward(padded_signal)\n",
    "reconstructed = pqmf.inverse(decomposed)\n",
    "\n",
    "print(signal.shape)\n",
    "print(decomposed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To play audio in the notebook (if using Jupyter)\n",
    "from IPython.display import Audio\n",
    "\n",
    "for i in range(decomposed.shape[1]):\n",
    "        # Convert to numpy array and specify the sample rate\n",
    "    audio_data = decomposed[0, i, :].cpu().numpy()\n",
    "    display(Audio(audio_data, rate=44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each band separately\n",
    "for i in range(decomposed.shape[1]):\n",
    "    signal = decomposed[0, i, :]\n",
    "    plot_waveform(signal, f\"Decomposed Signal - Band {i+1} (Time Domain)\")\n",
    "    plot_frequency_domain(signal, title=f\"Decomposed Signal - Band {i+1}\")\n",
    "    plot_spectrogram(signal, sr=44100, title=f\"Decomposed Signal - Band {i+1} (Spectrogram)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructed signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_waveform(reconstructed, \"Reconstructed Signal (Time Domain)\")\n",
    "plot_frequency_domain(reconstructed, title=\"Reconstructed Signal (Frequency Domain)\")\n",
    "plot_spectrogram(reconstructed, sr=44100, title=\"Reconstructed Signal (Spectrogram)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
